1.String类实现原理
private final char value[]

2.String类不为final会怎样
为了“效率”和“安全性”。
从效率讲：
1)字符串常量池失去意义。
2)若String允许被继承, 由于它的高度被使用率, 可能会降低程序的性能，所以String被定义成final。
3)另外，如果指定一个类为final，则该类所有的方法都是final。Java编译器会寻找机会内联（inline）所有的final方法（这和具体的编译器实现有关）。此举能够使性能平均提高50%。
从安全性讲：
1)不允许被继承，可以防止覆盖length()等方法。
2)private final char value[]，如果此数组可变，容易造成内存溢出。
3)String通常被作为键，如果可变则会破坏键的唯一性，也可能会引发线程安全问题。

3.HashMap实现原理
JDK1.8之前：数组和链表结合，即链表散列。key->hashCode->扰动函数，即hash方法，扰动4次，减少碰撞->hash->(n-1)&hash，n为数组长度->当前元素存放位置->key相同则覆盖，不同则拉链法解决冲突。
拉链法：创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。
JDK1.8之后：当链表长度大于阈值（默认为8）（将链表转换成红黑树前会判断，如果当前数组的长度小于64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

4.HashMap如何避免hash碰撞
1.7：
static int hash(int h) {
  h ^= (h >>> 20) ^ (h >>> 12);
  return h ^ (h >>> 7) ^ (h >>> 4);
}
1.8：
static final int hash(Object key) {
  int h;
  return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
^：按位异或
>>>：无符号右移，忽略符号位，空位都以0补齐
*1.8的hash方法性能稍好一些

5.SpringBoot自动配置原理
1)SpringBoot启动的时候加载主配置类，开启了自动配置功能@EnableAutoConfiguration
2)@EnableAutoConfiguration作用：
SpringFactoriesLoader.loadFactoryNames()
扫描所有jar包类路径下META‐INF/spring.factories
把扫描到的这些文件的内容包装成properties对象
从properties中获取到xxxAutoConfiguration.class类（类名）对应的值，然后把他们添加到容器中
3)每一个自动配置类进行自动配置功能
4)生效的配置类，会给容器中添加各种组件，这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的
5)所有在配置文件中能配置的属性都在xxxProperties类中封装着，配置文件能配置什么就可以参照某个功能对应的这个属性类
6)@Conditional控制配置类生不生效
7)通过启用debug=true属性，来让控制台打印自动配置报告，这样我们就可以很方便的知道哪些自动配置类生效

6.MySQL是怎么存储数据的（MyISAM和InnoDB）
1)MyISAM：
三个文件，后缀名为：frm、myi、myd。
frm文件：存储的是表结构信息。
myi文件：存储的是索引。
myd文件：存储的是数据。
2)InnoDB：
每个数据库对应一个文件夹，文件夹名和库名相同。
（单独的表空间中）每张表对应几个文件，文件名和表名相同，InnoDB引擎中对应两个文件，后缀名为：frm、ibd。
frm文件：存储的是表结构信息。
ibd文件：存储的是表里的数据、索引等。（默认以主键为索引，相当于将myi和myd合二为一）
ibd文件被分为连续的大小相同的区域，称为页（Page），大小默认值为16KB，可以设置。页的大小固定，格式固定。
多个Page在一起构成一颗多路平衡树, Page作为树的节点, 在平衡树的基础上, 同一层的节点左右相连, 所以称为B+树。
树中: 非叶子节点保存主键和子节点的位置, 叶子节点保存完整的记录。
B+Tree：
选用理由：
1)数组和链表的缺点就是不合适大数据量。
2)哈希是通过hash函数计算出一个hash值的，存在哈希碰撞的情况，另外哈希也不支持部分索引查询以及范围查找。
但是哈希的优点就是查找的时间复杂度是O(1)，那么什么情况下可以使用hash索引呢？就是查询条件不会变，而且没有部分查询和范围查询的时候。
3)红黑树存储的数据量大的时候，红黑树的节点层数多，也就是树的高度比较高，查找到底层数据时，查找次数就比较多，即对磁盘IO使用比较频繁。
总结为以下两点：
a.读取浪费太多：通过计算本来树的每一层大概需要分配16KB的数据，但是对于红黑树来说，实际存的节点数比较少，即存的数据大小远远小于16KB，从而造成存储空间的浪费。
b.读取磁盘的次数过多：树的层数越多，查找数据时读取磁盘的次数也就越多。
引出：
1)增加树每层的节点数量，这样可以对分配的16KB充分利用，即解决上面的读取浪费的问题。
2)尽可能的让树的高度减小，使得树显得比较“矮胖”，这样可以减少读取磁盘的次数。
比较：
B+Tree与BTree有啥不一样呢？B+Tree有以下几个特点：
1)叶子节点连起来了，是一条有序的双向链表，目的是为了解决范围查找。比如需要查找小于9的数据，只要找到等于9的数据，然后将9的左边数据全部拿出来即可。
2)非叶子节点不存数据，只存索引，空间利用更高效。
3)数据的个数和节点一样多，换句话说，非叶子节点存的是其子树的最大或最小值。
4)对于索引失效的情况，BTree是需要遍历整棵树才能把所有数据拿到，而B+Tree只需要找到叶子节点的第一个节点即可把所有数据拿到，可见效率是B+Tree更优，这就是双向链表的妙用。
特性：
1)单节点能存储更多数据，使得磁盘IO次数更少。
2)叶子节点形成有序链表，便于执行范围操作。
3)聚集索引中，叶子节点的data直接包含数据；非聚集索引中，叶子节点存储数据地址的指针。

7.MySQL索引常见优化手法
全值匹配、最左前缀、覆盖索引、避免失效

8.MySQL索引失效场景
1)查询列和索引列不一致
2)索引列上做计算、函数、转型等操作
3)不等于、is null、is not null
4)like以通配符开头
5)in的值太多
6)or连接

9.ES数据写入流程
1)数据写入->进入ES内存buffer（同时记录到translog）->生成倒排索引分片（segment）。
ES使用translog来记录所有的操作，称为write-ahead-log，新增一条记录时，ES会把数据写到translog和in-memory buffer（内存缓存区）中。
Lucene把每次生成的倒排索引，叫做一个segment（段），segment中的一条记录称为document（文档）。然后另外使用一个commit文件，用commit point记录索引内所有的segment的元数据。
2)将buffer中的segment先同步到文件系统缓存中，然后再调用fsync刷写到磁盘。
分片是一个底层的工作单元，一个分片是一个Lucene实例，它本身就是一个完整的搜索引擎，文档不会跨分片存储。
即一个ES的index包含多个shard（分片），一个shard包含多个segment，一个segment包含多个document...

补充：redis实现分布式锁
目的：解决并发问题，保证原子操作
可用性条件：
1)互斥性。在任何时刻，保证只有一个客户端持有锁。
2)不能出现死锁。如果在一个客户端持有锁的期间，这个客户端崩溃了，也要保证后续的其他客户端可以上锁。
3)保证上锁和解锁都是同一个客户端。
实现思路:
Redis实现分布式锁主要利用Redis的setnx命令。setnx是SET if not exists的简写。
127.0.0.1:6379> setnx lock value1 #在键lock不存在的情况下，将键key的值设置为value1
(integer) 1
127.0.0.1:6379> setnx lock value2 #试图覆盖lock的值，返回0表示失败
(integer) 0
127.0.0.1:6379> get lock #获取lock的值，验证没有被覆盖
"value1"
127.0.0.1:6379> del lock #删除lock的值，删除成功
(integer) 1
127.0.0.1:6379> setnx lock value2 #再使用setnx命令设置，返回1表示成功
(integer) 1
127.0.0.1:6379> get lock #获取lock的值，验证设置成功
"value2"
上面这几个命令就是最基本的用来完成分布式锁的命令。
加锁：使用setnx key value命令，如果key不存在，设置value（加锁成功）。如果已经存在lock（也就是有客户端持有锁了），则设置失败（加锁失败）。
解锁：使用del命令，通过删除键值释放锁。释放锁之后，其他客户端可以通过setnx命令进行加锁。
key的值可以根据业务设置，比如是用户中心使用的，可以命名为USER_REDIS_LOCK，value可以使用uuid保证唯一，用于标识加锁的客户端。保证加锁和解锁都是同一个客户端。
问题一：死锁
解决：超时机制，设置key的有效时间。
使用watchDog机制实现锁的续期。当加锁成功后，同时开启守护线程，默认有效期是30秒，每隔10秒就会给锁续期到30秒。
只要持有锁的客户端没有宕机，就能保证一直持有锁，直到业务代码执行完毕由客户端自己解锁，如果宕机了自然就在有效期失效后自动解锁。
问题二：可重入锁
解决：使用Redis的哈希表存储可重入次数，当加锁成功后，使用hset命令，value（重入次数）则是1。
如果同一个客户端再次加锁成功，则使用hincrby自增加一。
解锁时，先判断可重复次数是否大于0，大于0则减一，否则删除键值，释放锁资源。
为了保证操作原子性，加锁和解锁操作都是使用lua脚本执行。
问题三：加锁失败的情况下，若一直轮询尝试加锁，直到加锁成功为止，则太过耗费性能
解决：发布订阅机制
当加锁失败后，订阅锁释放的消息，自身进入阻塞状态。
当持有锁的客户端释放锁的时候，发布锁释放的消息。
当进入阻塞等待的其他客户端收到锁释放的消息后，解除阻塞等待状态，再次尝试加锁。
